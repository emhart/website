---
layout: post
title: "The open data challenge"
date: 2014-03-05 09:57:10 -0700
comments: true
tags: [data sharing, open data, publishing]
---

On the heels of the flurry of discussion about data sharing, I'm interested in expanding on [Greg Wilson's open scoop challenge](http://software-carpentry.org/blog/2014/02/open-scoop-challenge.html).  He is looking to find anyone who has been scooped by sharing their data.  This seems like a high bar to me.  So I'd like to lower it. Here's my thought experiment.  What data set exists that you can publish multiple papers from the exact same dataset? That is, you aren't just carving up a large dataset into [least publishable units](http://scientopia.org/blogs/drugmonkey/2009/01/22/repost-thoughts-on-the-least-publishable-unit/)? <!--more--> From my own experience I've collected data over the course of many field seasons of the same experiment and that might be considered a dataset. I've used different parts of that dataset to submit (and soon publish) multiple papers, but when I share the data, it will be the slice used to create the paper, not the entire dataset.  Then I'll have gotten all I can from it, and it's open to use.

I'm looking for anyone who has published multiple papers using the *exact* same dataset, and there could potentially have been scooped. Not the scenario above where there's a large dataset and people create publications based on slices of it.  In my reading of what PLoS requires (and I think is good to share) is the data required to recreate the paper,  and given that requirement it seems like it'd be hard to scoop anyone.  I'm just not sure what the scenario is where the exact same pieces of data are being used over and over again to get multiple publications.  Please leave references in the comments.
